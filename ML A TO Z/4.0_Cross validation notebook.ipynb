{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "In this section, we'll be learning about different cross-validation techniques you can use for ML models. We'll go over these cross validation techniques by analyzing a fraud detection dataset. At large tech companies, fraud becomes an important problem that directly affects the company's bottom line. For example, Uber had a HUGE fraud problem especially when they expanded into international markets. \n",
    "\n",
    "In this notebook, we'll be covering:\n",
    "\n",
    "- Train-Test-Split\n",
    "\n",
    "- Leave-One-Out Cross Validation\n",
    "\n",
    "- K-Fold Cross Validation\n",
    "\n",
    "- Date Split\n",
    "\n",
    "- Time Series Split\n",
    "\n",
    "- Expanding Window\n",
    "\n",
    "- Monte Carlo Cross Validation\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "First, we'll import the standard python libraries we commonly use for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Next, we'll load our fraud dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/sasivirat18/machine-learning-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\sasi virat\\Downloads\\learn-machine-learning-process-a-z\\Section 8\\2_Train-test-split\\Course notes\\fraud_data.csv\")\n",
    "\n",
    "## Sample down to improve speed\n",
    "pos = df[df['isFraud'] == 1].copy()\n",
    "neg = df[df['isFraud'] == 0].sample(100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pos, neg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split\n",
    "\n",
    "First method we'll go over is train-test-split. Train-test-split is the simplest form of cross-validation. We simply randomly slice our dataset into a training set and testing set. Typically, the most important parameters are: \n",
    "\n",
    "`X`: The feature set you're looking to split. \n",
    "\n",
    "`y`: The target variable you're looking to split.\n",
    "\n",
    "`test_size`: The size of your testing set. Typically, this is denoted as a fraction such as `0.33`. \n",
    "\n",
    "`random_state`: This is the seed of the random shuffle. I recommend setting a seed so everytime you rerun your notebook, your results stay consistent. \n",
    "\n",
    "`stratify`: This is an optional argument. But stratifying will reduce the variance in the random shuffle to ensure that your training and testing sets are more similar than not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9365562087407628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features = [\n",
    "    'amount',\n",
    "    'oldbalanceOrg',\n",
    "    'newbalanceOrig',\n",
    "    'oldbalanceDest',\n",
    "    'newbalanceDest'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['isFraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print(average_precision_score(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "\n",
    "The next common method of cross validation is K-Fold. To review, K-Fold is we’re essentially dividing our dataset into multiple datasets, then running train-test-split multiple times, across these subsets.\n",
    "\n",
    "Import parameters we should keep in mind: \n",
    "\n",
    "`n_splits`: This is the number of splits we want to make within our dataset. \n",
    "\n",
    "`shuffle`: This tells us whether we should shuffle our data before splitting into folds. \n",
    "\n",
    "`random_state`: This is the random seed we're setting, similar to train-test-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:         Unnamed: 0.1  Unnamed: 0  step      type    amount     nameOrig  \\\n",
      "0                  2           2     1  TRANSFER    181.00  C1305486145   \n",
      "2                251         251     1  TRANSFER   2806.00  C1420196421   \n",
      "5                681         681     1  CASH_OUT  20128.00  C1118430673   \n",
      "9               1115        1115     1  TRANSFER  35063.63  C1364127192   \n",
      "10              1116        1116     1  CASH_OUT  35063.63  C1635772897   \n",
      "...              ...         ...   ...       ...       ...          ...   \n",
      "108206       6168443     6168443   552   PAYMENT   1095.62  C1687711696   \n",
      "108207       4034532     4034532   299   PAYMENT   4138.25   C903315771   \n",
      "108209       3697512     3697512   277   PAYMENT   4293.86   C273464342   \n",
      "108210        290990      290990    15  CASH_OUT  63230.23  C1714577527   \n",
      "108211       2244408     2244408   186  CASH_OUT  72664.86  C1195779522   \n",
      "\n",
      "        oldbalanceOrg  newbalanceOrig     nameDest  oldbalanceDest  \\\n",
      "0              181.00            0.00   C553264065            0.00   \n",
      "2             2806.00            0.00   C972765878            0.00   \n",
      "5            20128.00            0.00   C339924917         6268.00   \n",
      "9            35063.63            0.00  C1136419747            0.00   \n",
      "10           35063.63            0.00  C1983025922        31140.00   \n",
      "...               ...             ...          ...             ...   \n",
      "108206      513902.00       512806.38  M1147896732            0.00   \n",
      "108207           0.00            0.00  M2039396301            0.00   \n",
      "108209           0.00            0.00  M1835506075            0.00   \n",
      "108210           0.00            0.00   C607769121       261617.62   \n",
      "108211       50903.00            0.00  C1131292799       126096.17   \n",
      "\n",
      "        newbalanceDest  isFraud  isFlaggedFraud        date  \n",
      "0                 0.00        1               0  2021-11-27  \n",
      "2                 0.00        1               0  2021-03-28  \n",
      "5             12145.85        1               0  2022-08-10  \n",
      "9                 0.00        1               0  2021-05-09  \n",
      "10             7550.03        1               0  2021-01-18  \n",
      "...                ...      ...             ...         ...  \n",
      "108206            0.00        0               0  2021-01-23  \n",
      "108207            0.00        0               0  2022-08-18  \n",
      "108209            0.00        0               0  2022-04-04  \n",
      "108210       324847.85        0               0  2021-05-29  \n",
      "108211       198761.03        0               0  2022-02-15  \n",
      "\n",
      "[54106 rows x 14 columns], test:         Unnamed: 0.1  Unnamed: 0  step      type      amount     nameOrig  \\\n",
      "1                  3           3     1  CASH_OUT      181.00   C840083671   \n",
      "3                252         252     1  CASH_OUT     2806.00  C2101527076   \n",
      "4                680         680     1  TRANSFER    20128.00   C137533655   \n",
      "6                724         724     1  CASH_OUT   416001.33   C749981943   \n",
      "7                969         969     1  TRANSFER  1277212.77  C1334405552   \n",
      "...              ...         ...   ...       ...         ...          ...   \n",
      "108203        770718      770718    39  CASH_OUT    66139.32  C1745202260   \n",
      "108204       2217660     2217660   186   PAYMENT    16303.81  C1790496183   \n",
      "108205        588060      588060    33   CASH_IN   143481.25   C713586511   \n",
      "108208       5035199     5035199   354   CASH_IN   118836.49  C1287414056   \n",
      "108212       1506185     1506185   144   PAYMENT    11615.55  C1645657139   \n",
      "\n",
      "        oldbalanceOrg  newbalanceOrig     nameDest  oldbalanceDest  \\\n",
      "1              181.00            0.00    C38997010        21182.00   \n",
      "3             2806.00            0.00  C1007251739        26202.00   \n",
      "4            20128.00            0.00  C1848415041            0.00   \n",
      "6                0.00            0.00   C667346055          102.00   \n",
      "7          1277212.77            0.00   C431687661            0.00   \n",
      "...               ...             ...          ...             ...   \n",
      "108203           0.00            0.00  C1117764929      1619784.28   \n",
      "108204       90706.28        74402.46   M944505877            0.00   \n",
      "108205        5588.00       149069.25   C743986730         7209.87   \n",
      "108208    21285752.56     21404589.05  C1436136891      5178610.82   \n",
      "108212        9942.00            0.00  M1156444073            0.00   \n",
      "\n",
      "        newbalanceDest  isFraud  isFlaggedFraud        date  \n",
      "1                 0.00        1               0  2021-01-01  \n",
      "3                 0.00        1               0  2022-05-20  \n",
      "4                 0.00        1               0  2021-09-28  \n",
      "6           9291619.62        1               0  2022-05-22  \n",
      "7                 0.00        1               0  2022-06-28  \n",
      "...                ...      ...             ...         ...  \n",
      "108203      1685923.60        0               0  2021-04-08  \n",
      "108204            0.00        0               0  2022-03-19  \n",
      "108205            0.00        0               0  2021-06-03  \n",
      "108208      5059774.33        0               0  2021-03-16  \n",
      "108212            0.00        0               0  2021-06-16  \n",
      "\n",
      "[54107 rows x 14 columns]\n",
      "train:         Unnamed: 0.1  Unnamed: 0  step      type      amount     nameOrig  \\\n",
      "1                  3           3     1  CASH_OUT      181.00   C840083671   \n",
      "3                252         252     1  CASH_OUT     2806.00  C2101527076   \n",
      "4                680         680     1  TRANSFER    20128.00   C137533655   \n",
      "6                724         724     1  CASH_OUT   416001.33   C749981943   \n",
      "7                969         969     1  TRANSFER  1277212.77  C1334405552   \n",
      "...              ...         ...   ...       ...         ...          ...   \n",
      "108203        770718      770718    39  CASH_OUT    66139.32  C1745202260   \n",
      "108204       2217660     2217660   186   PAYMENT    16303.81  C1790496183   \n",
      "108205        588060      588060    33   CASH_IN   143481.25   C713586511   \n",
      "108208       5035199     5035199   354   CASH_IN   118836.49  C1287414056   \n",
      "108212       1506185     1506185   144   PAYMENT    11615.55  C1645657139   \n",
      "\n",
      "        oldbalanceOrg  newbalanceOrig     nameDest  oldbalanceDest  \\\n",
      "1              181.00            0.00    C38997010        21182.00   \n",
      "3             2806.00            0.00  C1007251739        26202.00   \n",
      "4            20128.00            0.00  C1848415041            0.00   \n",
      "6                0.00            0.00   C667346055          102.00   \n",
      "7          1277212.77            0.00   C431687661            0.00   \n",
      "...               ...             ...          ...             ...   \n",
      "108203           0.00            0.00  C1117764929      1619784.28   \n",
      "108204       90706.28        74402.46   M944505877            0.00   \n",
      "108205        5588.00       149069.25   C743986730         7209.87   \n",
      "108208    21285752.56     21404589.05  C1436136891      5178610.82   \n",
      "108212        9942.00            0.00  M1156444073            0.00   \n",
      "\n",
      "        newbalanceDest  isFraud  isFlaggedFraud        date  \n",
      "1                 0.00        1               0  2021-01-01  \n",
      "3                 0.00        1               0  2022-05-20  \n",
      "4                 0.00        1               0  2021-09-28  \n",
      "6           9291619.62        1               0  2022-05-22  \n",
      "7                 0.00        1               0  2022-06-28  \n",
      "...                ...      ...             ...         ...  \n",
      "108203      1685923.60        0               0  2021-04-08  \n",
      "108204            0.00        0               0  2022-03-19  \n",
      "108205            0.00        0               0  2021-06-03  \n",
      "108208      5059774.33        0               0  2021-03-16  \n",
      "108212            0.00        0               0  2021-06-16  \n",
      "\n",
      "[54107 rows x 14 columns], test:         Unnamed: 0.1  Unnamed: 0  step      type    amount     nameOrig  \\\n",
      "0                  2           2     1  TRANSFER    181.00  C1305486145   \n",
      "2                251         251     1  TRANSFER   2806.00  C1420196421   \n",
      "5                681         681     1  CASH_OUT  20128.00  C1118430673   \n",
      "9               1115        1115     1  TRANSFER  35063.63  C1364127192   \n",
      "10              1116        1116     1  CASH_OUT  35063.63  C1635772897   \n",
      "...              ...         ...   ...       ...       ...          ...   \n",
      "108206       6168443     6168443   552   PAYMENT   1095.62  C1687711696   \n",
      "108207       4034532     4034532   299   PAYMENT   4138.25   C903315771   \n",
      "108209       3697512     3697512   277   PAYMENT   4293.86   C273464342   \n",
      "108210        290990      290990    15  CASH_OUT  63230.23  C1714577527   \n",
      "108211       2244408     2244408   186  CASH_OUT  72664.86  C1195779522   \n",
      "\n",
      "        oldbalanceOrg  newbalanceOrig     nameDest  oldbalanceDest  \\\n",
      "0              181.00            0.00   C553264065            0.00   \n",
      "2             2806.00            0.00   C972765878            0.00   \n",
      "5            20128.00            0.00   C339924917         6268.00   \n",
      "9            35063.63            0.00  C1136419747            0.00   \n",
      "10           35063.63            0.00  C1983025922        31140.00   \n",
      "...               ...             ...          ...             ...   \n",
      "108206      513902.00       512806.38  M1147896732            0.00   \n",
      "108207           0.00            0.00  M2039396301            0.00   \n",
      "108209           0.00            0.00  M1835506075            0.00   \n",
      "108210           0.00            0.00   C607769121       261617.62   \n",
      "108211       50903.00            0.00  C1131292799       126096.17   \n",
      "\n",
      "        newbalanceDest  isFraud  isFlaggedFraud        date  \n",
      "0                 0.00        1               0  2021-11-27  \n",
      "2                 0.00        1               0  2021-03-28  \n",
      "5             12145.85        1               0  2022-08-10  \n",
      "9                 0.00        1               0  2021-05-09  \n",
      "10             7550.03        1               0  2021-01-18  \n",
      "...                ...      ...             ...         ...  \n",
      "108206            0.00        0               0  2021-01-23  \n",
      "108207            0.00        0               0  2022-08-18  \n",
      "108209            0.00        0               0  2022-04-04  \n",
      "108210       324847.85        0               0  2021-05-29  \n",
      "108211       198761.03        0               0  2022-02-15  \n",
      "\n",
      "[54106 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle = True, random_state = 42)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "folds = {}\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    # Fold\n",
    "    fold_number = 1\n",
    "    # Store fold number\n",
    "    folds[fold_number] = (df.iloc[train], df.iloc[test])\n",
    "    print('train: %s, test: %s' % (df.iloc[train], df.iloc[test]))\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, after completing K-Fold Cross-Validation we'll want to calculate a cross-validation score. Typically, we'll get the scores for each fold, then take an average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993614441399188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out Cross Validation\n",
    "\n",
    "Another type of cross-validation is Leave One Out Cross-Validation. The idea here is that we’re training our model on all the data, then leaving one data point out, and evaluating our model on a single data point. We do this for every datapoint in the entire dataset. For the sake of time, we're goint to limit our dataset to 100 data points here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [0]\n",
      "TRAIN: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [1]\n",
      "TRAIN: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [2]\n",
      "TRAIN: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [3]\n",
      "TRAIN: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [4]\n",
      "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [5]\n",
      "TRAIN: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [6]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [7]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [8]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [9]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [10]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [11]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [12]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [13]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [14]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [15]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [16]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [17]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [18]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [19]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [20]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [21]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [22]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [23]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [24]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [25]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [26]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [27]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [28]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [29]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [30]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [31]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [32]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [33]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [34]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [35]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [36]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [37]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [38]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [39]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [40]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [41]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [42]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [43]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [44]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [45]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [46]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [47]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [48]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [49]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [50]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [51]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [52]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [53]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [54]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [55]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [56]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [57]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [58]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [59]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [60]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [61]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [62]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [63]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [64]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [65]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [66]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [67]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [68]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [69]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [70]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [71]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [72]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [73]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [74]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [75]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [76]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [77]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [78]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [79]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [80]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [81]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 83 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [82]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [83]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 85 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [84]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 86 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [85]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 87 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [86]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 88 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [87]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 89 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [88]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 90 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [89]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 91 92 93 94 95 96\n",
      " 97 98 99] TEST: [90]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 92 93 94 95 96\n",
      " 97 98 99] TEST: [91]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 93 94 95 96\n",
      " 97 98 99] TEST: [92]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 94 95 96\n",
      " 97 98 99] TEST: [93]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 95 96\n",
      " 97 98 99] TEST: [94]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 96\n",
      " 97 98 99] TEST: [95]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 97 98 99] TEST: [96]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 98 99] TEST: [97]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 99] TEST: [98]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98] TEST: [99]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "for train_index, test_index in loo.split(X[:100]):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    correct = y_preds[0] == y_test.values[0]\n",
    "    \n",
    "    all_preds.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_preds)/len(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split Date Split\n",
    "\n",
    "In many instances, you don't want to randomly slice your data into training and testing sets, but instead, you want to split it by time. In this case, you'll want to split by date: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9256972043566387\n"
     ]
    }
   ],
   "source": [
    "DATE = '2021-12-31'\n",
    "\n",
    "train_df = df[df['date'] < DATE].copy()\n",
    "test_df = df[df['date'] >= DATE].copy()\n",
    "\n",
    "X_train = train_df[features]\n",
    "X_test = test_df[features]\n",
    "\n",
    "y_train = train_df['isFraud']\n",
    "y_test = test_df['isFraud']\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print(average_precision_score(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window/Time Series KFold\n",
    "\n",
    "The problem with splitting by date is that the resulting training and testing sets can vary, depending on the date you select. The solution to this is to use a Time Series K-Fold Split. In time series Kfold, we're combining the elements of KFold and train-test date split. In Time Series Kfold, we'll be splitting our dataset multiple times, using differing dates. The size of the training sets will be the same for each fold: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.014139173828666482, 0.00748544496811755, 0.005988355974494039, 0.003936789575824785, 0.003271416689769892]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit()\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    pr_auc = average_precision_score(y_preds, y_test)\n",
    "    \n",
    "    all_scores.append(pr_auc)\n",
    "    \n",
    "    \n",
    "print(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Window\n",
    "\n",
    "One of the problems with standard time series split, is the size of the training sets stay the same. The solution to this is to use an expanding window split. The idea here, is with each incremental date split, we're using **all** the data rather than sliding the window. You can adapt the sci-kit learn version of TimeSeriesSplit. We also wrote a simple implementation as well: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ExpandingWindowCV.split at 0x00000232BAC74260>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExpandingWindowCV:\n",
    "    def fit(self, date_col, date_range = None, custom_range = None):\n",
    "        self.date_col = date_col\n",
    "        self.date_range = date_range\n",
    "        self.custom_range = custom_range\n",
    "        \n",
    "        if date_range is not None and custom_range is not None:\n",
    "            raise ValueError(\"Date Range and Custom Range both cannot be None.\")\n",
    "    \n",
    "    def split(self, df):\n",
    "        if self.date_range is None:         \n",
    "            dates = list(set(df[self.date_col].astype(str).values))\n",
    "        \n",
    "        if self.date_range is not None:\n",
    "            dates = pd.date_range(start=self.date_range[0], end=self.date_range[1])\n",
    "            dates = [str(d.date()) for d in dates]\n",
    "        \n",
    "        if self.custom_range is not None:\n",
    "            dates = self.custom_range\n",
    "            \n",
    "        for d in dates:\n",
    "            df_train = df[df[self.date_col].astype(str) <= d].copy()\n",
    "            df_test = df[df[self.date_col].astype(str) > d].copy()\n",
    "            yield df_train, df_test\n",
    "            \n",
    "ew = ExpandingWindowCV()\n",
    "ew.fit(date_col = 'date', date_range = ['2022-01-02','2022-01-08'])\n",
    "ew.split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9289116170553807,\n",
       " 0.925293537439552,\n",
       " 0.9264024160105822,\n",
       " 0.9232142542951964,\n",
       " 0.9287578373092636,\n",
       " 0.9249475252101106,\n",
       " 0.9221430900864206]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for train_df, test_df in ew.split(df):\n",
    "    X_train = train_df[features]\n",
    "    X_test = test_df[features]\n",
    "\n",
    "    y_train = train_df['isFraud']\n",
    "    y_test = test_df['isFraud']\n",
    "\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    pr_auc = average_precision_score(y_preds, y_test)\n",
    "    \n",
    "    all_scores.append(pr_auc)\n",
    "    \n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Cross Validation\n",
    "\n",
    "The last method we'll go over is Monte Carlo Cross Validation. Monte Carlos Cross Validation is where we randomly select a sub-sample (with replacement) from our dataset for the training set, use the rest for the testing set. Repeat this (with replacement) N number of times, to create a distribution of evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
    "rs.get_n_splits(df)\n",
    "\n",
    "all_scores = []\n",
    "for train_index, test_index in rs.split(df):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    pr_auc = average_precision_score(y_preds, y_test)\n",
    "    \n",
    "    all_scores.append(pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9385855916413093,\n",
       " 0.9346739723802807,\n",
       " 0.923244691789708,\n",
       " 0.9410443687251063,\n",
       " 0.9336379776499611]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, you learned about a variety of cross validation techniques: \n",
    "\n",
    "- Train-Test-Split\n",
    "\n",
    "- Leave-One-Out Cross Validation\n",
    "\n",
    "- K-Fold Cross Validation\n",
    "\n",
    "- Date Split\n",
    "\n",
    "- Time Series Split\n",
    "\n",
    "- Expanding Window\n",
    "\n",
    "- Monte Carlo Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "- [Understanding 8 types of Cross-Validation by Satyam Kumar](https://towardsdatascience.com/understanding-8-types-of-cross-validation-80c935a4976d)\n",
    "- [7 Types of Cross Validation by Soumyaa Rawat](https://www.analyticssteps.com/blogs/7-types-cross-validation)\n",
    "- [k-fold cross-validation explained in plain English by Rukshan Pramoditha](https://towardsdatascience.com/k-fold-cross-validation-explained-in-plain-english-659e33c0bc0)\n",
    "- [Machine Learning Fundamentals: Bias and Variance by Josh Starmer/Statquest](https://www.youtube.com/watch?v=EuBBz3bI-aA&t=4s&ab_channel=StatQuestwithJoshStarmer)\n",
    "- [A Quick Intro to Leave-One-Out Cross-Validation (LOOCV) by Statology](https://www.statology.org/leave-one-out-cross-validation/)\n",
    "- [Time Series Cross Validation by Robert Hyndman](https://otexts.com/fpp3/tscv.html)\n",
    "- [Time Based Cross Validation](https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8)\n",
    "- [KFold vs. Monte Carlo by Rebecca Patro](https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
